{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Matheus\\Documents\\Git\\GPT-projeto-crs-PT-BR\\venv_crs\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading data: 100%|██████████| 6.61M/6.61M [00:01<00:00, 3.56MB/s]\n",
      "Downloading data: 100%|██████████| 835k/835k [00:00<00:00, 940kB/s]t]\n",
      "Downloading data files: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]\n",
      "Extracting data files: 100%|██████████| 2/2 [00:00<00:00, 145.18it/s]\n",
      "Generating train split: 10006 examples [00:00, 239908.80 examples/s]\n",
      "Generating test split: 1342 examples [00:00, 170372.18 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds_train = load_dataset(\"re_dial\", revision=\"refs/convert/parquet\", split=\"train\")\n",
    "ds_test = load_dataset(\"re_dial\", revision=\"refs/convert/parquet\", split=\"test\")\n",
    "\n",
    "ds_train.to_pandas().to_parquet(\"data/raw/train.parquet\")\n",
    "ds_test.to_pandas().to_parquet(\"data/raw/test.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Interim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "interim_path = 'data/processed/translated_ds_011.parquet'\n",
    "\n",
    "df = pd.read_parquet(interim_path)\n",
    "print(f'total de linhas: {len(df)}')\n",
    "\n",
    "# non_translated_count = df['text_translated'].isna().sum()\n",
    "# translated_count = len(df) - non_translated_count\n",
    "\n",
    "# print(f'Total de mensagens traduzidas: {translated_count}')\n",
    "# print(f'Total de mensagens não traduzidas: {non_translated_count}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Carregando o dataset\n",
    "\n",
    "PATH = 'data/raw/ds.parquet'\n",
    "\n",
    "df = pd.read_parquet(PATH)\n",
    "\n",
    "# Dividindo o dataframe em 10 partes\n",
    "splits = np.array_split(df, 10)\n",
    "\n",
    "# Salvando cada parte como um arquivo parquet separado\n",
    "for idx, split in enumerate(splits, 1):\n",
    "    filename = f'data/raw/ds_{idx:03}.parquet'\n",
    "    split.to_parquet(filename, index=False)\n",
    "    print(f\"Saved {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example generating batchs samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "PATH = 'data/processed'\n",
    "df_train = []\n",
    "all_movies = []\n",
    "\n",
    "df = []\n",
    "\n",
    "for filename in os.listdir(PATH):\n",
    "\n",
    "    if filename.endswith('.parquet') and filename != 'translated_ds_011.parquet':\n",
    "        df.append(pd.read_parquet(os.path.join(PATH, filename)))\n",
    "\n",
    "df_train = pd.concat(df).reset_index(drop=True)\n",
    "df_test = pd.read_parquet('data/processed/translated_ds_011.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_movies = [j['movieName'] for i in df_train['movieMentions'].tolist() for j in i]\n",
    "all_movies.extend([j['movieName'] for i in df_test['movieMentions'].tolist() for j in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload df_train and df_test to huggingface datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "ds_train = Dataset.from_pandas(df_train)\n",
    "ds_test = Dataset.from_pandas(df_test)\n",
    "\n",
    "# ds_train.save_to_disk('data/processed/ds_train')\n",
    "# ds_test.save_to_disk('data/processed/ds_test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 10/10 [00:00<00:00, 58.82ba/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:02<00:00,  2.59s/it]\n",
      "Deleting unused files from dataset repository: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Downloading metadata: 100%|██████████| 1.45k/1.45k [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "ds_train.push_to_hub(\"matheusrdgsf/re_dial_ptbr\", split=\"train\")\n",
    "ds_test.push_to_hub(\"matheusrdgsf/re_dial_ptbr\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"conversationId\": 391, \"messages\": [{\"messageId\": 1021, \"senderWorkerId\": 0, \"text\": \"Hi there, how are you? I\\'m looking for movie recommendations\", \"timeOffset\": 0}, {\"messageId\": 1022, \"senderWorkerId\": 1, \"text\": \"I am doing okay. What kind of movies do you like?\", \"timeOffset\": 15}, {\"messageId\": 1023, \"senderWorkerId\": 0, \"text\": \"I like animations like @84779 and @191602\", \"timeOffset\": 66}, {\"messageId\": 1024, \"senderWorkerId\": 0, \"text\": \"I also enjoy @122159\", \"timeOffset\": 86}, {\"messageId\": 1025, \"senderWorkerId\": 0, \"text\": \"Anything artistic\", \"timeOffset\": 95}, {\"messageId\": 1026, \"senderWorkerId\": 1, \"text\": \"You might like @165710 that was a good movie.\", \"timeOffset\": 135}, {\"messageId\": 1027, \"senderWorkerId\": 0, \"text\": \"What\\'s it about?\", \"timeOffset\": 151}, {\"messageId\": 1028, \"senderWorkerId\": 1, \"text\": \"It has Alec Baldwin it is about a baby that works for a company and gets adopted it is very funny\", \"timeOffset\": 207}, {\"messageId\": 1029, \"senderWorkerId\": 0, \"text\": \"That seems like a nice comedy\", \"timeOffset\": 238}, {\"messageId\": 1030, \"senderWorkerId\": 0, \"text\": \"Do you have any animated recommendations that are a bit more dramatic? Like @151313 for example\", \"timeOffset\": 272}, {\"messageId\": 1031, \"senderWorkerId\": 0, \"text\": \"I like comedies but I prefer films with a little more depth\", \"timeOffset\": 327}, {\"messageId\": 1032, \"senderWorkerId\": 1, \"text\": \"That is a tough one but I will remember something\", \"timeOffset\": 467}, {\"messageId\": 1033, \"senderWorkerId\": 1, \"text\": \"@203371 was a good one\", \"timeOffset\": 509}, {\"messageId\": 1034, \"senderWorkerId\": 0, \"text\": \"Ooh that seems cool! Thanks for the input. I\\'m ready to submit if you are.\", \"timeOffset\": 564}, {\"messageId\": 1035, \"senderWorkerId\": 1, \"text\": \"It is animated, sci fi, and has action\", \"timeOffset\": 571}, {\"messageId\": 1036, \"senderWorkerId\": 1, \"text\": \"Glad I could help\", \"timeOffset\": 579}, {\"messageId\": 1037, \"senderWorkerId\": 0, \"text\": \"Nice\", \"timeOffset\": 581}, {\"messageId\": 1038, \"senderWorkerId\": 0, \"text\": \"Take care, cheers!\", \"timeOffset\": 591}, {\"messageId\": 1039, \"senderWorkerId\": 1, \"text\": \"bye\", \"timeOffset\": 608}], \"messages_translated\": [{\"messageId\": 1021, \"senderWorkerId\": 0, \"text\": \"Olá, como você está? Estou procurando recomendações de filmes.\", \"timeOffset\": 0}, {\"messageId\": 1022, \"senderWorkerId\": 1, \"text\": \"Eu estou indo bem. Qual tipo de filmes você gosta?\", \"timeOffset\": 15}, {\"messageId\": 1023, \"senderWorkerId\": 0, \"text\": \"Eu gosto de animações como @84779 e @191602.\", \"timeOffset\": 66}, {\"messageId\": 1024, \"senderWorkerId\": 0, \"text\": \"Eu também gosto de @122159.\", \"timeOffset\": 86}, {\"messageId\": 1025, \"senderWorkerId\": 0, \"text\": \"Qualquer coisa artística\", \"timeOffset\": 95}, {\"messageId\": 1026, \"senderWorkerId\": 1, \"text\": \"Você pode gostar de saber que foi um bom filme.\", \"timeOffset\": 135}, {\"messageId\": 1027, \"senderWorkerId\": 0, \"text\": \"O que é isso?\", \"timeOffset\": 151}, {\"messageId\": 1028, \"senderWorkerId\": 1, \"text\": \"Tem um bebê que trabalha para uma empresa e é adotado. É muito engraçado.\", \"timeOffset\": 207}, {\"messageId\": 1029, \"senderWorkerId\": 0, \"text\": \"Isso parece ser uma comédia legal.\", \"timeOffset\": 238}, {\"messageId\": 1030, \"senderWorkerId\": 0, \"text\": \"Você tem alguma recomendação animada que seja um pouco mais dramática, como por exemplo @151313?\", \"timeOffset\": 272}, {\"messageId\": 1031, \"senderWorkerId\": 0, \"text\": \"Eu gosto de comédias, mas prefiro filmes com um pouco mais de profundidade.\", \"timeOffset\": 327}, {\"messageId\": 1032, \"senderWorkerId\": 1, \"text\": \"Isso é um desafio, mas eu me lembrarei de algo.\", \"timeOffset\": 467}, {\"messageId\": 1033, \"senderWorkerId\": 1, \"text\": \"@203371 Foi um bom dia.\", \"timeOffset\": 509}, {\"messageId\": 1034, \"senderWorkerId\": 0, \"text\": \"Ah, parece legal! Obrigado pela contribuição. Estou pronto para enviar se você estiver.\", \"timeOffset\": 564}, {\"messageId\": 1035, \"senderWorkerId\": 1, \"text\": \"É animado, de ficção científica e tem ação.\", \"timeOffset\": 571}, {\"messageId\": 1036, \"senderWorkerId\": 1, \"text\": \"Fico feliz em poder ajudar.\", \"timeOffset\": 579}, {\"messageId\": 1037, \"senderWorkerId\": 0, \"text\": \"Legal\", \"timeOffset\": 581}, {\"messageId\": 1038, \"senderWorkerId\": 0, \"text\": \"Cuide-se, abraços!\", \"timeOffset\": 591}, {\"messageId\": 1039, \"senderWorkerId\": 1, \"text\": \"Adeus\", \"timeOffset\": 608}], \"movieMentions\": [{\"movieId\": \"203371\", \"movieName\": \"Final Fantasy: The Spirits Within (2001)\"}, {\"movieId\": \"84779\", \"movieName\": \"The Triplets of Belleville (2003)\"}, {\"movieId\": \"122159\", \"movieName\": \"Mary and Max (2009)\"}, {\"movieId\": \"151313\", \"movieName\": \"A Scanner Darkly  (2006)\"}, {\"movieId\": \"191602\", \"movieName\": \"Waking Life (2001)\"}, {\"movieId\": \"165710\", \"movieName\": \"The Boss Baby (2017)\"}], \"respondentQuestions\": [{\"liked\": 1, \"movieId\": \"203371\", \"seen\": 0, \"suggested\": 1}, {\"liked\": 1, \"movieId\": \"84779\", \"seen\": 1, \"suggested\": 0}, {\"liked\": 1, \"movieId\": \"122159\", \"seen\": 1, \"suggested\": 0}, {\"liked\": 1, \"movieId\": \"151313\", \"seen\": 1, \"suggested\": 0}, {\"liked\": 1, \"movieId\": \"191602\", \"seen\": 1, \"suggested\": 0}, {\"liked\": 1, \"movieId\": \"165710\", \"seen\": 0, \"suggested\": 1}], \"respondentWorkerId\": 1, \"initiatorWorkerId\": 0, \"initiatorQuestions\": [{\"liked\": 1, \"movieId\": \"203371\", \"seen\": 0, \"suggested\": 1}, {\"liked\": 1, \"movieId\": \"84779\", \"seen\": 1, \"suggested\": 0}, {\"liked\": 1, \"movieId\": \"122159\", \"seen\": 1, \"suggested\": 0}, {\"liked\": 1, \"movieId\": \"151313\", \"seen\": 1, \"suggested\": 0}, {\"liked\": 1, \"movieId\": \"191602\", \"seen\": 1, \"suggested\": 0}, {\"liked\": 1, \"movieId\": \"165710\", \"seen\": 0, \"suggested\": 1}]}'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.dumps(example, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id2text(text, movies):\n",
    "    for movie_id in re.findall(r'@\\d+', text):\n",
    "        if movies[movies['movieId'] == movie_id[1:]].empty:\n",
    "            movie_name = '<unk>'\n",
    "        else:\n",
    "            movie_name = movies[movies['movieId'] == movie_id[1:]]['movieName'].iloc[0]\n",
    "        text = text.replace(movie_id, movie_name)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.DataFrame(df['movieMentions'].explode().drop_duplicates().dropna().reset_index(drop=True).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V1 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9005/9005 [01:10<00:00, 126.91it/s]\n"
     ]
    }
   ],
   "source": [
    "#from string import punctuation\n",
    "#from tqdm import tqdm\n",
    "\n",
    "#dict_punctuation = {i: j for j, i in enumerate(punctuation)}\n",
    "\n",
    "#df_train = []\n",
    "# df = pd.read_parquet('data/processed/translated_ds_011.parquet')\n",
    "\n",
    "# for _, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "#     df_explode = pd.DataFrame(row[['messages_translated']].explode().tolist())\n",
    "#     # print(df_explode)\n",
    "#     df_explode['text'] = df_explode.apply(lambda x: id2text(x['text'], movies), axis=1)\n",
    "#     #print(df_explode.iloc[0])\n",
    "#     worker_id = df_explode.iloc[0]['senderWorkerId']\n",
    "#     instruction = ''\n",
    "#     response = ''\n",
    "\n",
    "#     changed = False\n",
    "\n",
    "#     for index, message in df_explode.iterrows():\n",
    "        \n",
    "#         if changed == False:\n",
    "#             if message['senderWorkerId'] == worker_id:\n",
    "#                 instruction += message['text']\n",
    "#                 if instruction[-1] not in dict_punctuation:\n",
    "#                     instruction+='.'\n",
    "#             else:\n",
    "#                 changed = True\n",
    "#                 response += message['text']\n",
    "#                 if response[-1] not in dict_punctuation:\n",
    "#                     response+='.'\n",
    "#         else:\n",
    "#             if message['senderWorkerId'] != worker_id:\n",
    "#                 response += message['text']\n",
    "#                 if response[-1] not in dict_punctuation:\n",
    "#                     response+='.'\n",
    "#             else:\n",
    "#                 changed = False\n",
    "#                 df_train.append({'initiator': instruction, 'respondant': response})\n",
    "#                 response = ''\n",
    "#                 instruction = message['text']\n",
    "#                 if instruction[-1] not in dict_punctuation:\n",
    "#                     instruction+='.'\n",
    "# df_train = pd.DataFrame(df_train)\n",
    "\n",
    "# def generate_sample(conversation):\n",
    "#         return \"<|system|>\\n Você é um chatbot de recomendação de filmes, converse com o usuário para indicar filmes apropriados.</s>\\n<|user|>\\n\" + conversation['initiator'] + \"</s>\\n<|assistant|>\\n\" + conversation['respondant'] + \"</s>\\n\"\n",
    "\n",
    "# df_train['sample'] = df_train.apply(lambda x: generate_sample(x), axis=1)\n",
    "# df_train.drop(['initiator', 'respondant'], axis=1, inplace=True)\n",
    "\n",
    "# df_train.to_parquet('data/processed/test.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V2 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{% for message in messages %}\\n{% if message['role'] == 'user' %}\\n{{ '<|user|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'system' %}\\n{{ '<|system|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'assistant' %}\\n{{ '<|assistant|>\\n'  + message['content'] + eos_token }}\\n{% endif %}\\n{% if loop.last and add_generation_prompt %}\\n{{ '<|assistant|>' }}\\n{% endif %}\\n{% endfor %}\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceH4/zephyr-7b-alpha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|system|>\\nVocê é um chatbot para indicação de filmes. Responda de maneira educada sugestões de filmes para os usuários.</s>\\n<|user|>\\nHi there!</s>\\n<|assistant|>\\nNice to meet you!</s>\\n<|user|>\\nCan I ask a question?</s>\\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Você é um chatbot para indicação de filmes. Responda de maneira educada sugestões de filmes para os usuários.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hi there!\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Nice to meet you!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can I ask a question?\"}\n",
    "]\n",
    "\n",
    "tokenizer.apply_chat_template(messages, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1342/1342 [00:08<00:00, 166.81it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from string import punctuation\n",
    "from tqdm import tqdm\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceH4/zephyr-7b-alpha\")\n",
    "\n",
    "def process_dataset(df, movies):\n",
    "    \n",
    "    dataset = []\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        df_explode = pd.DataFrame(row[['messages_translated']].explode().tolist())\n",
    "        df_explode['text'] = df_explode.apply(lambda x: id2text(x['text'], movies), axis=1)\n",
    "        worker_id = df_explode.iloc[0]['senderWorkerId']\n",
    "\n",
    "        message_template = [{\"role\": \"system\", \"content\": \"Você é um chatbot para indicação de filmes. Responda de maneira educada sugestões de filmes para os usuários.\"}]\n",
    "\n",
    "        for index, message in df_explode.iterrows():\n",
    "            \n",
    "            if message['senderWorkerId'] == worker_id:\n",
    "                message_template.append({\"role\": \"user\", \"content\": message['text']})\n",
    "            else:\n",
    "                message_template.append({\"role\": \"assistant\", \"content\": message['text']})\n",
    "\n",
    "        dataset.append(tokenizer.apply_chat_template(message_template, tokenize=False))\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# Train\n",
    "df_train = process_dataset(df, movies)\n",
    "\n",
    "# Test\n",
    "df_test = pd.read_parquet('data/processed/translated_ds_011.parquet')\n",
    "movies_test = pd.DataFrame(df_test['movieMentions'].explode().drop_duplicates().dropna().reset_index(drop=True).tolist())\n",
    "df_test = process_dataset(pd.read_parquet('data/processed/translated_ds_011.parquet'), movies_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df_train, columns=['sample']).to_parquet('data/processed/colab/v2/train.parquet', index=False)\n",
    "pd.DataFrame(df_test, columns=['sample']).to_parquet('data/processed/colab/v2/test.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save dataset to hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df_train, columns=['sample']).to_parquet('data/processed/colab/v2/train.parquet', index=False)\n",
    "pd.DataFrame(df_test, columns=['sample']).to_parquet('data/processed/colab/v2/test.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_parquet('data/processed/colab/v2/train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|system|>\\nVocê é um chatbot para indicação de filmes. Responda de maneira educada sugestões de filmes para os usuários.</s>\\n<|user|>\\nOlá, como você está? Estou procurando recomendações de filmes.</s>\\n<|assistant|>\\nEu estou indo bem. Qual tipo de filmes você gosta?</s>\\n<|user|>\\nEu gosto de animações como The Triplets of Belleville (2003) e Waking Life (2001).</s>\\n<|user|>\\nEu também gosto de Mary and Max (2009).</s>\\n<|user|>\\nQualquer coisa artística</s>\\n<|assistant|>\\nVocê pode gostar de saber que foi um bom filme.</s>\\n<|user|>\\nO que é isso?</s>\\n<|assistant|>\\nTem um bebê que trabalha para uma empresa e é adotado. É muito engraçado.</s>\\n<|user|>\\nIsso parece ser uma comédia legal.</s>\\n<|user|>\\nVocê tem alguma recomendação animada que seja um pouco mais dramática, como por exemplo A Scanner Darkly  (2006)?</s>\\n<|user|>\\nEu gosto de comédias, mas prefiro filmes com um pouco mais de profundidade.</s>\\n<|assistant|>\\nIsso é um desafio, mas eu me lembrarei de algo.</s>\\n<|assistant|>\\nFinal Fantasy: The Spirits Within (2001) Foi um bom dia.</s>\\n<|user|>\\nAh, parece legal! Obrigado pela contribuição. Estou pronto para enviar se você estiver.</s>\\n<|assistant|>\\nÉ animado, de ficção científica e tem ação.</s>\\n<|assistant|>\\nFico feliz em poder ajudar.</s>\\n<|user|>\\nLegal</s>\\n<|user|>\\nCuide-se, abraços!</s>\\n<|assistant|>\\nAdeus</s>\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['sample'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Matheus\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def regex_movies(text):\n",
    "  text = text.replace('\"', '')\n",
    "  regex = r'\\b[A-Z][a-zA-Z]+(?:\\s[A-Z][A-Za-z]+)*\\s\\(\\d{4}\\)'\n",
    "  movies = re.findall(regex, text)\n",
    "\n",
    "  return list(set(movies))\n",
    "\n",
    "def get_similarity(text_a, text_b):\n",
    "  similarity = fuzz.ratio(text_a, text_b)\n",
    "  return similarity\n",
    "\n",
    "def compute_metrics(data, threshold=80):\n",
    "\n",
    "  expected_movies = data['expected_movies']\n",
    "  #print(expected_movies)\n",
    "\n",
    "  # Has Movie\n",
    "  pred_movies = data['pred_movies']\n",
    "  #print(pred_movies)\n",
    "\n",
    "  # Hits\n",
    "  hits = 0\n",
    "  for pred_movie in pred_movies:\n",
    "    for expected_movie in expected_movies:\n",
    "      if fuzz.ratio(pred_movie, expected_movie) > threshold:\n",
    "        # print(fuzz.ratio(pred_movie, expected_movie))\n",
    "        hits+=1\n",
    "\n",
    "  # salvar csv com data_eval['context'], data_eval['response'], completion, inference_tinme, has_movie, hits\n",
    "\n",
    "\n",
    "  return {\n",
    "      'has_movie': 1 if pred_movies else 0,\n",
    "      'hits': hits\n",
    "  }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cesar = pd.read_parquet('data/results/test_8B_ours_generated_3.parquet')\n",
    "gptq = pd.read_parquet('data/results/test_gptq_8b_sf_generated.parquet')\n",
    "base = pd.read_parquet('data/results/test_base_sf_generated.parquet')\n",
    "# pd.DataFrame(all_movies, columns=['movieName']).to_csv('data/results/all_movies.csv', index=False)\n",
    "all_movies = pd.read_csv('data/results/all_movies.csv')\n",
    "\n",
    "cesar['pred_movies'] = cesar['generated_response'].apply(lambda x: regex_movies(x))\n",
    "gptq['pred_movies'] = gptq['generated_response'].apply(lambda x: regex_movies(x))\n",
    "base['pred_movies'] = base['generated_response'].apply(lambda x: regex_movies(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cesar[['has_movie', 'hits']] = cesar.apply(lambda x: compute_metrics(x), axis=1, result_type='expand')\n",
    "gptq[['has_movie', 'hits']] = gptq.apply(lambda x: compute_metrics(x), axis=1, result_type='expand')\n",
    "base[['has_movie', 'hits']] = base.apply(lambda x: compute_metrics(x), axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has_movie\n",
      "1    0.851351\n",
      "0    0.148649\n",
      "dtype: float64\n",
      "hits\n",
      "0    0.905405\n",
      "1    0.081081\n",
      "2    0.013514\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(cesar.value_counts('has_movie', normalize=True))\n",
    "print(cesar.value_counts('hits', normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has_movie\n",
      "1    0.783784\n",
      "0    0.216216\n",
      "dtype: float64\n",
      "hits\n",
      "0    0.851351\n",
      "1    0.135135\n",
      "2    0.013514\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(gptq.value_counts('has_movie', normalize=True))\n",
    "print(gptq.value_counts('hits', normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has_movie\n",
      "1    0.783784\n",
      "0    0.216216\n",
      "dtype: float64\n",
      "hits\n",
      "0    0.837838\n",
      "1    0.148649\n",
      "2    0.013514\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(base.value_counts('has_movie', normalize=True))\n",
    "print(base.value_counts('hits', normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"papluca/xlm-roberta-base-language-detection\")\n",
    "\n",
    "cesar['language'] = cesar['generated_response'].apply(lambda x: pipe(x))\n",
    "gptq['language'] = gptq['generated_response'].apply(lambda x: pipe(x))\n",
    "base['language'] = base['generated_response'].apply(lambda x: pipe(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cesar['majority_language'] = cesar['language'].apply(lambda x: x[0]['label'])\n",
    "gptq['majority_language'] = gptq['language'].apply(lambda x: x[0]['label'])\n",
    "base['majority_language'] = base['language'].apply(lambda x: x[0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt    0.783784\n",
      "en    0.216216\n",
      "Name: majority_language, dtype: float64\n",
      "pt    0.702703\n",
      "en    0.297297\n",
      "Name: majority_language, dtype: float64\n",
      "pt    0.716216\n",
      "en    0.283784\n",
      "Name: majority_language, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(cesar['majority_language'].value_counts(normalize=True))\n",
    "print(gptq['majority_language'].value_counts(normalize=True))\n",
    "print(base['majority_language'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversationId</th>\n",
       "      <th>instruction</th>\n",
       "      <th>expected_response</th>\n",
       "      <th>expected_movies</th>\n",
       "      <th>generated_response</th>\n",
       "      <th>pred_movies</th>\n",
       "      <th>language</th>\n",
       "      <th>majority_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20041</td>\n",
       "      <td>&lt;|system|&gt;\\nVocê é um chatbot para indicação d...</td>\n",
       "      <td>Claro! Eu gosto muito de comédias. Eu gosto de...</td>\n",
       "      <td>[Hot Tub Time Machine, Super Troopers (2001), ...</td>\n",
       "      <td>\\n&lt;|assistant|&gt;\\nSim, claro! Qualquer coisa es...</td>\n",
       "      <td>[La La Land (2016), Before Sunrise (1995), Cra...</td>\n",
       "      <td>[{'label': 'pt', 'score': 0.995539128780365}]</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20115</td>\n",
       "      <td>&lt;|system|&gt;\\nVocê é um chatbot para indicação d...</td>\n",
       "      <td>Eu gostei do House at the End of the Street (2...</td>\n",
       "      <td>[House at the End of the Street (2012), The La...</td>\n",
       "      <td>\\n&lt;|assistant|&gt;\\nCerto! Se você gostar de film...</td>\n",
       "      <td>[Halloween (1978)]</td>\n",
       "      <td>[{'label': 'pt', 'score': 0.9951830506324768}]</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20185</td>\n",
       "      <td>&lt;|system|&gt;\\nVocê é um chatbot para indicação d...</td>\n",
       "      <td>Eu amo It  (2017) e It (1990). Sim, eles são a...</td>\n",
       "      <td>[It  (2017), It (1990), A Quiet Place (2018)]</td>\n",
       "      <td>\\n&lt;|assistant|&gt;\\nSim, o filme It (2017) é um r...</td>\n",
       "      <td>[It (2017)]</td>\n",
       "      <td>[{'label': 'pt', 'score': 0.9951711297035217}]</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20193</td>\n",
       "      <td>&lt;|system|&gt;\\nVocê é um chatbot para indicação d...</td>\n",
       "      <td>Há mais de dois, A Nightmare on Elm Street 3: ...</td>\n",
       "      <td>[A Nightmare on Elm Street 3: Dream Warriors (...</td>\n",
       "      <td>\\n&lt;|assistant|&gt;\\nEu concordo com você. O antig...</td>\n",
       "      <td>[It (1990)]</td>\n",
       "      <td>[{'label': 'pt', 'score': 0.9949414134025574}]</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20194</td>\n",
       "      <td>&lt;|system|&gt;\\nVocê é um chatbot para indicação d...</td>\n",
       "      <td>Ele tem Adam Sandler nele. Eu gosto de tantos ...</td>\n",
       "      <td>[Billy Madison (1995), Big Daddy  (1999), Litt...</td>\n",
       "      <td>\\n&lt;|user|&gt;\\nEntão, se você gostou dos dois pri...</td>\n",
       "      <td>[American Reunion (2012), Superbad (2007), Bri...</td>\n",
       "      <td>[{'label': 'pt', 'score': 0.9954119324684143}]</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>23116</td>\n",
       "      <td>&lt;|system|&gt;\\nVocê é um chatbot para indicação d...</td>\n",
       "      <td>Bem, eu recomendo os filmes de Superman Classi...</td>\n",
       "      <td>[Superman Classic, 3 Avengers, Batman ]</td>\n",
       "      <td>Então, se você gosta de super-heróis, eu recom...</td>\n",
       "      <td>[Endgame (2019), Black Panther (2018)]</td>\n",
       "      <td>[{'label': 'pt', 'score': 0.995036780834198}]</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>23152</td>\n",
       "      <td>&lt;|system|&gt;\\nVocê é um chatbot para indicação d...</td>\n",
       "      <td>Claro, na verdade The Dark Knight Rises (2012)...</td>\n",
       "      <td>[The Dark Knight Rises (2012), Zodiac  (2007),...</td>\n",
       "      <td>Certainly! Based on your preference for \"Seven...</td>\n",
       "      <td>[Prisoners (2013), Gone Girl (2014), Seven (19...</td>\n",
       "      <td>[{'label': 'en', 'score': 0.9714609384536743}]</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>23191</td>\n",
       "      <td>&lt;|system|&gt;\\nVocê é um chatbot para indicação d...</td>\n",
       "      <td>Bem, há muitos filmes como Fight Club (1999), ...</td>\n",
       "      <td>[Fight Club (1999), Choke  (2008), The Machini...</td>\n",
       "      <td>\\n&lt;|assistant|&gt;\\nNatural Born Killers é um clá...</td>\n",
       "      <td>[List (1993), Forrest Gump (1994), The Godfath...</td>\n",
       "      <td>[{'label': 'pt', 'score': 0.9958732724189758}]</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>23248</td>\n",
       "      <td>&lt;|system|&gt;\\nVocê é um chatbot para indicação d...</td>\n",
       "      <td>Bem, há muitos filmes assim, um é o Trading Pl...</td>\n",
       "      <td>[Trading Places (1983), The Man Who Knew Too M...</td>\n",
       "      <td>Olá! Se você gostou de What About Bob? (1991),...</td>\n",
       "      <td>[Analyze This (1999), Good Will Hunting (1997)]</td>\n",
       "      <td>[{'label': 'pt', 'score': 0.9952507019042969}]</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>23320</td>\n",
       "      <td>&lt;|system|&gt;\\nVocê é um chatbot para indicação d...</td>\n",
       "      <td>Final Fantasy: The Spirits Within (2001) The H...</td>\n",
       "      <td>[Final Fantasy: The Spirits Within (2001), The...</td>\n",
       "      <td>\\n&lt;|assistant|&gt;\\nCertainly! If you're in the m...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'label': 'en', 'score': 0.9852412343025208}]</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    conversationId                                        instruction  \\\n",
       "0            20041  <|system|>\\nVocê é um chatbot para indicação d...   \n",
       "1            20115  <|system|>\\nVocê é um chatbot para indicação d...   \n",
       "2            20185  <|system|>\\nVocê é um chatbot para indicação d...   \n",
       "3            20193  <|system|>\\nVocê é um chatbot para indicação d...   \n",
       "4            20194  <|system|>\\nVocê é um chatbot para indicação d...   \n",
       "..             ...                                                ...   \n",
       "69           23116  <|system|>\\nVocê é um chatbot para indicação d...   \n",
       "70           23152  <|system|>\\nVocê é um chatbot para indicação d...   \n",
       "71           23191  <|system|>\\nVocê é um chatbot para indicação d...   \n",
       "72           23248  <|system|>\\nVocê é um chatbot para indicação d...   \n",
       "73           23320  <|system|>\\nVocê é um chatbot para indicação d...   \n",
       "\n",
       "                                    expected_response  \\\n",
       "0   Claro! Eu gosto muito de comédias. Eu gosto de...   \n",
       "1   Eu gostei do House at the End of the Street (2...   \n",
       "2   Eu amo It  (2017) e It (1990). Sim, eles são a...   \n",
       "3   Há mais de dois, A Nightmare on Elm Street 3: ...   \n",
       "4   Ele tem Adam Sandler nele. Eu gosto de tantos ...   \n",
       "..                                                ...   \n",
       "69  Bem, eu recomendo os filmes de Superman Classi...   \n",
       "70  Claro, na verdade The Dark Knight Rises (2012)...   \n",
       "71  Bem, há muitos filmes como Fight Club (1999), ...   \n",
       "72  Bem, há muitos filmes assim, um é o Trading Pl...   \n",
       "73  Final Fantasy: The Spirits Within (2001) The H...   \n",
       "\n",
       "                                      expected_movies  \\\n",
       "0   [Hot Tub Time Machine, Super Troopers (2001), ...   \n",
       "1   [House at the End of the Street (2012), The La...   \n",
       "2       [It  (2017), It (1990), A Quiet Place (2018)]   \n",
       "3   [A Nightmare on Elm Street 3: Dream Warriors (...   \n",
       "4   [Billy Madison (1995), Big Daddy  (1999), Litt...   \n",
       "..                                                ...   \n",
       "69            [Superman Classic, 3 Avengers, Batman ]   \n",
       "70  [The Dark Knight Rises (2012), Zodiac  (2007),...   \n",
       "71  [Fight Club (1999), Choke  (2008), The Machini...   \n",
       "72  [Trading Places (1983), The Man Who Knew Too M...   \n",
       "73  [Final Fantasy: The Spirits Within (2001), The...   \n",
       "\n",
       "                                   generated_response  \\\n",
       "0   \\n<|assistant|>\\nSim, claro! Qualquer coisa es...   \n",
       "1   \\n<|assistant|>\\nCerto! Se você gostar de film...   \n",
       "2   \\n<|assistant|>\\nSim, o filme It (2017) é um r...   \n",
       "3   \\n<|assistant|>\\nEu concordo com você. O antig...   \n",
       "4   \\n<|user|>\\nEntão, se você gostou dos dois pri...   \n",
       "..                                                ...   \n",
       "69  Então, se você gosta de super-heróis, eu recom...   \n",
       "70  Certainly! Based on your preference for \"Seven...   \n",
       "71  \\n<|assistant|>\\nNatural Born Killers é um clá...   \n",
       "72  Olá! Se você gostou de What About Bob? (1991),...   \n",
       "73  \\n<|assistant|>\\nCertainly! If you're in the m...   \n",
       "\n",
       "                                          pred_movies  \\\n",
       "0   [La La Land (2016), Before Sunrise (1995), Cra...   \n",
       "1                                  [Halloween (1978)]   \n",
       "2                                         [It (2017)]   \n",
       "3                                         [It (1990)]   \n",
       "4   [American Reunion (2012), Superbad (2007), Bri...   \n",
       "..                                                ...   \n",
       "69             [Endgame (2019), Black Panther (2018)]   \n",
       "70  [Prisoners (2013), Gone Girl (2014), Seven (19...   \n",
       "71  [List (1993), Forrest Gump (1994), The Godfath...   \n",
       "72    [Analyze This (1999), Good Will Hunting (1997)]   \n",
       "73                                                 []   \n",
       "\n",
       "                                          language majority_language  \n",
       "0    [{'label': 'pt', 'score': 0.995539128780365}]                pt  \n",
       "1   [{'label': 'pt', 'score': 0.9951830506324768}]                pt  \n",
       "2   [{'label': 'pt', 'score': 0.9951711297035217}]                pt  \n",
       "3   [{'label': 'pt', 'score': 0.9949414134025574}]                pt  \n",
       "4   [{'label': 'pt', 'score': 0.9954119324684143}]                pt  \n",
       "..                                             ...               ...  \n",
       "69   [{'label': 'pt', 'score': 0.995036780834198}]                pt  \n",
       "70  [{'label': 'en', 'score': 0.9714609384536743}]                en  \n",
       "71  [{'label': 'pt', 'score': 0.9958732724189758}]                pt  \n",
       "72  [{'label': 'pt', 'score': 0.9952507019042969}]                pt  \n",
       "73  [{'label': 'en', 'score': 0.9852412343025208}]                en  \n",
       "\n",
       "[74 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cesar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
